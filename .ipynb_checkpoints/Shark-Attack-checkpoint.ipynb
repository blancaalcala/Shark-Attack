{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import SRC.function as F\n",
    "import re\n",
    "df = pd.read_csv(\"INPUT/GSAF5.csv\", encoding = \"cp1252\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of values:  5992\n",
      "\n",
      "Total count of NaN values: \n",
      "\n",
      " Case Number                  0\n",
      "Date                         0\n",
      "Year                         0\n",
      "Type                         0\n",
      "Country                     43\n",
      "Area                       402\n",
      "Location                   496\n",
      "Activity                   527\n",
      "Name                       200\n",
      "Sex                        567\n",
      "Age                       2681\n",
      "Injury                      27\n",
      "Fatal (Y/N)                 19\n",
      "Time                      3213\n",
      "Species                   2934\n",
      "Investigator or Source      15\n",
      "pdf                          0\n",
      "href formula                 1\n",
      "href                         3\n",
      "Case Number.1                0\n",
      "Case Number.2                0\n",
      "original order               0\n",
      "Unnamed: 22               5991\n",
      "Unnamed: 23               5990\n",
      "dtype: int64\n",
      "\n",
      "Columns to drop: \n",
      " Unnamed: 22 Unnamed: 23\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with NaN values for all or almost all elements\n",
    "\n",
    "null_cols = df.isnull().sum()\n",
    "dim = df.shape\n",
    "print(\"\\nTotal number of values: \",dim[0])\n",
    "print(\"\\nTotal count of NaN values: \\n\\n\",null_cols)\n",
    "\n",
    "# we remove columns with at least 90% of NaN\n",
    "\n",
    "drop_cols = list(null_cols[null_cols > df.shape[0]*0.9].index)\n",
    "print(\"\\nColumns to drop: \\n\",*drop_cols)\n",
    "df = df.drop(drop_cols,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common elements between Case Number and Case Number.1: 5979 (99.78%)\n",
      "Common elements between Case Number and Case Number.2: 5990 (99.97%)\n",
      "Common elements between href and href formula: 5938 (99.1%)\n"
     ]
    }
   ],
   "source": [
    "# the next step is to remove similar columns\n",
    "# we can also delete columns \"Case Number.1\" and \"Case Number.2\", as they are very similar to \"Case Number\" column\n",
    "                             \n",
    "drop1 = sum(df[\"Case Number\"]==df[\"Case Number.1\"])\n",
    "drop2 = sum(df[\"Case Number\"]==df[\"Case Number.2\"])\n",
    "                           \n",
    "print(\"\\nCommon elements between Case Number and Case Number.1: {} ({}%)\".format(drop1,round(drop1*100/dim[0],2)))\n",
    "print(\"Common elements between Case Number and Case Number.2: {} ({}%)\".format(drop2,round(drop2*100/dim[0],2)))\n",
    "\n",
    "df = df.drop([\"Case Number.1\",\"Case Number.2\"],axis=1)\n",
    "\n",
    "# because \"href\" and \"href formula\" are the same, one of them can also be removed\n",
    "\n",
    "drop3 = sum(df[\"href\"]==df[\"href formula\"])\n",
    "                           \n",
    "print(\"Common elements between href and href formula: {} ({}%)\".format(drop3,round(drop3*100/dim[0],2)))\n",
    "df = df.drop([\"href formula\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "no rows can be removed as they all provide a significant amount of information\n"
     ]
    }
   ],
   "source": [
    "# we can check if there are any rows with a high amount of NaN\n",
    "\n",
    "df_rows = df.T\n",
    "null_rows = df_rows.isnull().sum()\n",
    "print(max(null_rows))\n",
    "\n",
    "print(\"no rows can be removed as they all provide a significant amount of information\")\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# we must check if there are any duplicate rows \n",
    "\n",
    "duplicates = df[df.duplicated()]\n",
    "print(len(duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Number               object\n",
      "Date                      object\n",
      "Year                       int64\n",
      "Type                      object\n",
      "Country                   object\n",
      "Area                      object\n",
      "Location                  object\n",
      "Activity                  object\n",
      "Name                      object\n",
      "Sex                       object\n",
      "Age                       object\n",
      "Injury                    object\n",
      "Fatal (Y/N)               object\n",
      "Time                      object\n",
      "Species                   object\n",
      "Investigator or Source    object\n",
      "pdf                       object\n",
      "href                      object\n",
      "original order             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# First we check all the columns and the data type of each one of them\n",
    "\n",
    "print(df.dtypes)\n",
    "df = df.astype(str)\n",
    "df = df.fillna(\"0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################### DATE #########################################################\n",
    "date = df[\"Date\"]\n",
    "year = df[\"Year\"]\n",
    "for y in range(0,len(year)):\n",
    "    if re.search(\"\\d\\d\\d\\d\",year[y])==None:\n",
    "        df[\"Year\"][y] = \"Unknown\"\n",
    "        \n",
    "    \n",
    "for x in range(0,len(date)):\n",
    "    if re.search(\"(?i)\\d\\d-\\w\\w\\w-\\d\\d\\d\\d\",date[x]):\n",
    "        if re.search(\"(?i)Reported\\s\\d\\d-\\w\\w\\w-\\d\\d\\d\\d\",date[x]):\n",
    "            df[\"Date\"][x] = re.findall(\"(?i)\\d\\d-\\w\\w\\w-\\d\\d\\d\\d\",date[x])\n",
    "    else:\n",
    "        if re.search(\"(?i)\\d\\d-\\w\\w\\w-\\d\\d\",date[x]):\n",
    "            df[\"Date\"][x] = date[x][0:2]+\"-\"+date[x][3:6]+\"-\"+year[x]\n",
    "        elif re.search(\"(?i)\\s?\\w\\w\\w-\\d\\d$\",date[x]):\n",
    "            if year[x]!=\"Unknown\":\n",
    "                df[\"Date\"][x] = \"XX-\"+date[x][0:3]+\"-\"+year[x]\n",
    "            else:\n",
    "                df[\"Date\"][x] = \"Unknown\"\n",
    "        elif re.search(\"(?i)^\\d\\d\\d\\d$\",date[x]):\n",
    "            df[\"Date\"][x] = \"DD-MMMM-\"+date[x]\n",
    "        else: \n",
    "            if year[x]!=\"Unknown\":\n",
    "                df[\"Date\"][x] = \"XX-MMM-\"+year[x]\n",
    "            else:\n",
    "                df[\"Date\"][x] = \"Unknown\"\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### CASE NUMBER ########################################################\n",
    "\n",
    "date = list(df[\"Case Number\"])\n",
    "n = 0\n",
    "for i in range(0,len(date)):\n",
    "    date[i] = re.sub(\"\\.\",\"/\",date[i])\n",
    "    date[i] = date[i][0:10]\n",
    "    df[\"Case Number\"][i] = date[i]    \n",
    "for i in range(0,len(date)):   \n",
    "    if date[i][5:10] == \"00/00\":\n",
    "        df[\"Case Number\"][i] = date[i][0:4]\n",
    "    elif date[i][0:2]==\"ND\":\n",
    "        n += 1\n",
    "        df[\"Case Number\"][i] = \"Unidentified #{}\".format(n)\n",
    "\n",
    "        \n",
    "# we set an ID for each case also print date and reorder the data according to original order column, which can be removed\n",
    "for c in range(0,len(date)):\n",
    "    df[\"Case Number\"][c] = str(c)  \n",
    "\n",
    "df = df.drop([\"original order\"], axis=1)\n",
    "df = df.rename(columns=({\"Case Number\":\"Case Id\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprovoked    4916\n",
      "Provoked       557\n",
      "Unknown        519\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################################################## TYPE ########################################################\n",
    "\n",
    "F.renameF(df,\"Type\",\"Boat\",\"Unprovoked\")\n",
    "F.renameF(df,\"Type\",\"Boating\",\"Unprovoked\")\n",
    "F.renameF(df,\"Type\",\"Invalid\",\"Unknown\")\n",
    "F.renameF(df,\"Type\",\"Sea Disaster\",\"Unprovoked\")\n",
    "\n",
    "print(df[\"Type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################### ACTIVITY ########################################################\n",
    "\n",
    "e = df[\"Activity\"]\n",
    "\n",
    "kite = e.apply(F.findF,args=(\"kite|board|kayak|cano|sail|wake|row\",))\n",
    "dive = e.apply(F.findF,args=(\"div\",))\n",
    "swim = e.apply(F.findF,args=(\"swim|wad|snork|water|float|bath\",))\n",
    "fish = e.apply(F.findF,args=(\"fish|collect\",))\n",
    "surf = e.apply(F.findF,args=(\"surf\",))\n",
    "\n",
    "for i in range(len(e)):\n",
    "    if kite[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Water sports\"\n",
    "    elif dive[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Diving\"\n",
    "    elif swim[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Swimming\"\n",
    "    elif fish[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Fishing\"\n",
    "    elif surf[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Surfing\"\n",
    "    else:\n",
    "        df[\"Activity\"][i] = \"Other\"\n",
    "    \n",
    "\n",
    "\n",
    "print(df[\"Activity\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Country'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-167-aac143164aa4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Country\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#print(df[\"Country\"].unique())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Country'"
     ]
    }
   ],
   "source": [
    "print(df[\"Country\"])\n",
    "#print(df[\"Country\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "names = df[\"Name\"].tolist()\n",
    "for n in names:\n",
    "    if re.search(\"[A-Z][a-z]\\s[A-Z][a-z]+\",n)==None:\n",
    "        df[\"Name\"] = df[\"Name\"].replace(n,\"Unknown\")\n",
    "    \n",
    "df[\"Name\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SURVIVAL ###################################################\n",
    "\n",
    "survival = df[\"Fatal (Y/N)\"]\n",
    "serie = F.Fatality(survival)\n",
    "#print(df[\"Survival\"].value_counts())\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-98-fcea98100da4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#change values in %%h%%m format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\d\\d+\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0msplit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"h\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m\"12\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/3.7.4_1/Frameworks/Python.framework/Versions/3.7/lib/python3.7/re.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    181\u001b[0m     \"\"\"Scan through string looking for a match to the pattern, returning\n\u001b[1;32m    182\u001b[0m     a Match object, or None if no match was found.\"\"\"\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "################################################### TIME #############################################################\n",
    "\n",
    "#check unique values to unify time information\n",
    "\n",
    "for t in range(0,len(df_new[\"Time\"])):\n",
    "    time = df_new[\"Time\"][t]\n",
    "#change values in %%h%%m format\n",
    "    if re.search(\"\\d\\d+\",time):\n",
    "        split = (re.split(\"h\",time))\n",
    "        if split[0] < \"12\":\n",
    "            df_new[\"Time\"][t] = \"Morning\"\n",
    "        elif split[0]>\"12\" and split[0]<\"16\":\n",
    "            df_new[\"Time\"][t] = \"Afternoon\"\n",
    "        elif split[0]>\"16\" and split[0]<\"20\":\n",
    "            df_new[\"Time\"][t]=\"Evening\"\n",
    "        else:\n",
    "            df_new[\"Time\"][t] = \"Night\"    \n",
    "#change other formats\n",
    "    Morning = [\"Dawn\",\"AM\",\"A.M.\",\"daybreak\",\"morning\"]\n",
    "    Afternoon = [\"After\",\"Midday\",\"noon\",\"lunch\",\"Daytime\"]\n",
    "    Evening = [\"P.M.\",\"PM\",\"Evening\",\"dusk\",\"sunset\",\"sundown\"]\n",
    "    Night = [\"night\",\"Dark\"]\n",
    "    for m in Morning:\n",
    "        F.find_Time(df_new,\"Time\",time,t,m,\"Morning\")\n",
    "    for a in Afternoon:\n",
    "        F.find_Time(df_new,\"Time\",time,t,a,\"Afternoon\")\n",
    "    for e in Evening:\n",
    "        F.find_Time(df_new,\"Time\",time,t,e,\"Evening\")        \n",
    "    for n in Night:\n",
    "        F.find_Time(df_new,\"Time\",time,t,n,\"Night\")            \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "    unknown = [\"x\",\"0\",\"--\",\"\\xa0\",\"  \",\"   \",\" \"]\n",
    "    for u in unknown:\n",
    "        if re.match(\"(?i)\"+u,time):\n",
    "            F.find_Time(df_new,\"Time\",time,t,u,\"Unknown\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_new[\"Time\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
