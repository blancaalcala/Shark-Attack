{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import SRC.function as F\n",
    "import re\n",
    "df = pd.read_csv(\"INPUT/GSAF5.csv\", encoding = \"cp1252\")\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total number of values:  5992\n",
      "\n",
      "Total count of NaN values: \n",
      "\n",
      " Case Number                  0\n",
      "Date                         0\n",
      "Year                         0\n",
      "Type                         0\n",
      "Country                     43\n",
      "Area                       402\n",
      "Location                   496\n",
      "Activity                   527\n",
      "Name                       200\n",
      "Sex                        567\n",
      "Age                       2681\n",
      "Injury                      27\n",
      "Fatal (Y/N)                 19\n",
      "Time                      3213\n",
      "Species                   2934\n",
      "Investigator or Source      15\n",
      "pdf                          0\n",
      "href formula                 1\n",
      "href                         3\n",
      "Case Number.1                0\n",
      "Case Number.2                0\n",
      "original order               0\n",
      "Unnamed: 22               5991\n",
      "Unnamed: 23               5990\n",
      "dtype: int64\n",
      "\n",
      "Columns to drop: \n",
      " Unnamed: 22 Unnamed: 23\n"
     ]
    }
   ],
   "source": [
    "# Remove columns with NaN values for all or almost all elements\n",
    "\n",
    "null_cols = df.isnull().sum()\n",
    "dim = df.shape\n",
    "print(\"\\nTotal number of values: \",dim[0])\n",
    "print(\"\\nTotal count of NaN values: \\n\\n\",null_cols)\n",
    "\n",
    "# we remove columns with at least 90% of NaN\n",
    "\n",
    "drop_cols = list(null_cols[null_cols > df.shape[0]*0.9].index)\n",
    "print(\"\\nColumns to drop: \\n\",*drop_cols)\n",
    "df = df.drop(drop_cols,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Common elements between Case Number and Case Number.1: 5979 (99.78%)\n",
      "Common elements between Case Number and Case Number.2: 5990 (99.97%)\n",
      "Common elements between href and href formula: 5938 (99.1%)\n"
     ]
    }
   ],
   "source": [
    "# the next step is to remove similar columns\n",
    "# we can also delete columns \"Case Number.1\" and \"Case Number.2\", as they are very similar to \"Case Number\" column\n",
    "                             \n",
    "drop1 = sum(df[\"Case Number\"]==df[\"Case Number.1\"])\n",
    "drop2 = sum(df[\"Case Number\"]==df[\"Case Number.2\"])\n",
    "                           \n",
    "print(\"\\nCommon elements between Case Number and Case Number.1: {} ({}%)\".format(drop1,round(drop1*100/dim[0],2)))\n",
    "print(\"Common elements between Case Number and Case Number.2: {} ({}%)\".format(drop2,round(drop2*100/dim[0],2)))\n",
    "\n",
    "df = df.drop([\"Case Number.1\",\"Case Number.2\"],axis=1)\n",
    "\n",
    "# because \"href\" and \"href formula\" are the same, one of them can also be removed\n",
    "\n",
    "drop3 = sum(df[\"href\"]==df[\"href formula\"])\n",
    "                           \n",
    "print(\"Common elements between href and href formula: {} ({}%)\".format(drop3,round(drop3*100/dim[0],2)))\n",
    "df = df.drop([\"href formula\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "no rows can be removed as they all provide a significant amount of information\n"
     ]
    }
   ],
   "source": [
    "# we can check if there are any rows with a high amount of NaN\n",
    "\n",
    "df_rows = df.T\n",
    "null_rows = df_rows.isnull().sum()\n",
    "print(max(null_rows))\n",
    "\n",
    "print(\"no rows can be removed as they all provide a significant amount of information\")\n",
    "\n",
    "#df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# we must check if there are any duplicate rows \n",
    "\n",
    "duplicates = df[df.duplicated()]\n",
    "print(len(duplicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case Number               object\n",
      "Date                      object\n",
      "Year                       int64\n",
      "Type                      object\n",
      "Country                   object\n",
      "Area                      object\n",
      "Location                  object\n",
      "Activity                  object\n",
      "Name                      object\n",
      "Sex                       object\n",
      "Age                       object\n",
      "Injury                    object\n",
      "Fatal (Y/N)               object\n",
      "Time                      object\n",
      "Species                   object\n",
      "Investigator or Source    object\n",
      "pdf                       object\n",
      "href                      object\n",
      "original order             int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# First we check all the columns and the data type of each one of them\n",
    "\n",
    "print(df.dtypes)\n",
    "df = df.astype(str)\n",
    "df = df.fillna(\"0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################################### DATE #########################################################\n",
    "date = df[\"Date\"]\n",
    "year = df[\"Year\"]\n",
    "for y in range(0,len(year)):\n",
    "    if re.search(\"\\d\\d\\d\\d\",year[y])==None:\n",
    "        df[\"Year\"][y] = \"Unknown\"\n",
    "        \n",
    "    \n",
    "for x in range(0,len(date)):\n",
    "    if re.search(\"(?i)\\d\\d-\\w\\w\\w-\\d\\d\\d\\d\",date[x]):\n",
    "        if re.search(\"(?i)Reported\\s\\d\\d-\\w\\w\\w-\\d\\d\\d\\d\",date[x]):\n",
    "            df[\"Date\"][x] = re.findall(\"(?i)\\d\\d-\\w\\w\\w-\\d\\d\\d\\d\",date[x])\n",
    "    else:\n",
    "        if re.search(\"(?i)\\d\\d-\\w\\w\\w-\\d\\d\",date[x]):\n",
    "            df[\"Date\"][x] = date[x][0:2]+\"-\"+date[x][3:6]+\"-\"+year[x]\n",
    "        elif re.search(\"(?i)\\s?\\w\\w\\w-\\d\\d$\",date[x]):\n",
    "            if year[x]!=\"Unknown\":\n",
    "                df[\"Date\"][x] = \"XX-\"+date[x][0:3]+\"-\"+year[x]\n",
    "            else:\n",
    "                df[\"Date\"][x] = \"Unknown\"\n",
    "        elif re.search(\"(?i)^\\d\\d\\d\\d$\",date[x]):\n",
    "            df[\"Date\"][x] = \"DD-MMMM-\"+date[x]\n",
    "        else: \n",
    "            if year[x]!=\"Unknown\":\n",
    "                df[\"Date\"][x] = \"XX-MMM-\"+year[x]\n",
    "            else:\n",
    "                df[\"Date\"][x] = \"Unknown\"\n",
    "            \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################### CASE NUMBER ########################################################\n",
    "\n",
    "date = list(df[\"Case Number\"])\n",
    "n = 0\n",
    "for i in range(0,len(date)):\n",
    "    date[i] = re.sub(\"\\.\",\"/\",date[i])\n",
    "    date[i] = date[i][0:10]\n",
    "    df[\"Case Number\"][i] = date[i]    \n",
    "for i in range(0,len(date)):   \n",
    "    if date[i][5:10] == \"00/00\":\n",
    "        df[\"Case Number\"][i] = date[i][0:4]\n",
    "    elif date[i][0:2]==\"ND\":\n",
    "        n += 1\n",
    "        df[\"Case Number\"][i] = \"Unidentified #{}\".format(n)\n",
    "\n",
    "        \n",
    "# we set an ID for each case also print date and reorder the data according to original order column, which can be removed\n",
    "for c in range(0,len(date)):\n",
    "    df[\"Case Number\"][c] = str(c)  \n",
    "\n",
    "df = df.drop([\"original order\"], axis=1)\n",
    "df = df.rename(columns=({\"Case Number\":\"Case Id\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unprovoked    4916\n",
      "Provoked       557\n",
      "Unknown        519\n",
      "Name: Type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "######################################################## TYPE ########################################################\n",
    "\n",
    "F.renameF(df,\"Type\",\"Boat\",\"Unprovoked\")\n",
    "F.renameF(df,\"Type\",\"Boating\",\"Unprovoked\")\n",
    "F.renameF(df,\"Type\",\"Invalid\",\"Unknown\")\n",
    "F.renameF(df,\"Type\",\"Sea Disaster\",\"Unprovoked\")\n",
    "\n",
    "print(df[\"Type\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Surfing' 'Fishing' 'Swimming' 'Water sports' 'Other' 'Diving']\n"
     ]
    }
   ],
   "source": [
    "#################################################### ACTIVITY ########################################################\n",
    "\n",
    "e = df[\"Activity\"]\n",
    "\n",
    "kite = e.apply(F.findF,args=(\"kite|board|kayak|cano|sail|wake|row\",))\n",
    "dive = e.apply(F.findF,args=(\"div\",))\n",
    "swim = e.apply(F.findF,args=(\"swim|wad|snork|water|float|bath\",))\n",
    "fish = e.apply(F.findF,args=(\"fish|collect\",))\n",
    "surf = e.apply(F.findF,args=(\"surf\",))\n",
    "\n",
    "for i in range(len(e)):\n",
    "    if kite[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Water sports\"\n",
    "    elif dive[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Diving\"\n",
    "    elif swim[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Swimming\"\n",
    "    elif fish[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Fishing\"\n",
    "    elif surf[i]!=None:\n",
    "        df[\"Activity\"][i] = \"Surfing\"\n",
    "    else:\n",
    "        df[\"Activity\"][i] = \"Other\"\n",
    "    \n",
    "\n",
    "\n",
    "print(df[\"Activity\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['USA' 'Australia' 'New Caledonia' 'Reunion' 'Bahamas' 'Spain' 'China'\n",
      " 'Japan' 'Columbia' 'South Africa' 'Egypt' 'New Zealand' 'Indonesia'\n",
      " 'French Polynesia' 'Cape Verde' 'Fiji' 'Brazil' 'Dominican Republic'\n",
      " 'Cayman Islands' 'United Arab Emirates' 'Aruba' 'Mozambique' 'Thailand'\n",
      " 'Puerto Rico' 'Italy' 'Mexico' 'Atlantic Ocean' 'Greece' 'Mauritius'\n",
      " 'Nan' 'St. Martin' 'France' 'Ecuador' 'Papua New Guinea'\n",
      " 'Trinidad & Tobago' 'Kiribati' 'Israel' 'Diego Garcia' 'Taiwan' 'Jamaica'\n",
      " 'Palestinian Territories' 'Guam' 'Seychelles' 'Belize' 'Philippines'\n",
      " 'Nigeria' 'Tonga' 'Scotland' 'Canada' 'Croatia' 'Saudi Arabia' 'Chile'\n",
      " 'Antigua' 'Kenya' 'Russia' 'Turks & Caicos' 'Costa Rica' 'United Kingdom'\n",
      " 'Malaysia' 'UNITED ARAB EMIRATES (UAE)' 'Samoa' 'Azores'\n",
      " 'Solomon Islands' 'South Korea' 'Malta' 'Vietnam' 'Madagascar' 'Panama'\n",
      " 'Somalia' 'Nevis' 'Cuba' 'England' 'British Virgin Islands' 'Norway'\n",
      " 'Senegal' 'Yemen' 'Gulf Of Aden' 'Sierra Leone' 'St. Maartin'\n",
      " 'Grand Cayman' 'Liberia' 'Vanuatu' 'Mexico ' 'Honduras' 'Venezuela'\n",
      " 'Sri Lanka' ' Tonga' 'Uruguay' 'India' 'Micronesia' 'Caribbean Sea'\n",
      " 'Okinawa' 'Tanzania' 'Marshall Islands' 'Egypt / Israel'\n",
      " 'Northern Arabian Sea' 'Hong Kong' 'El Salvador' 'Angola' 'Bermuda'\n",
      " 'Montenegro' 'Iran' 'Tunisia' 'Namibia' 'North Atlantic Ocean' 'Portugal'\n",
      " 'South China Sea' 'Bangladesh' 'Palau' 'Western Samoa' 'Pacific Ocean '\n",
      " 'British Isles' 'Grenada' 'Iraq' 'Turkey' 'Singapore' 'New Britain'\n",
      " 'Sudan' 'Johnston Island' 'South Pacific Ocean' 'New Guinea' 'Red Sea'\n",
      " 'North Pacific Ocean' 'Federated States Of Micronesia'\n",
      " 'Mid Atlantic Ocean' 'Admiralty Islands' 'British West Indies'\n",
      " 'South Atlantic Ocean' 'Persian Gulf' 'Red Sea / Indian Ocean'\n",
      " 'Pacific Ocean' 'North Sea' 'Nicaragua ' 'Maldive Islands'\n",
      " 'American Samoa' 'Andaman / Nicobar Islandas' 'Gabon' 'Mayotte'\n",
      " 'North Atlantic Ocean ' 'The Balkans' 'Argentina' 'Martinique'\n",
      " 'Indian Ocean' 'Guatemala' 'Netherlands Antilles'\n",
      " 'Northern Mariana Islands' 'Iran / Iraq' 'Java' ' Philippines'\n",
      " 'Nicaragua' 'Central Pacific' 'Solomon Islands / Vanuatu'\n",
      " 'Southwest Pacific Ocean' 'Bay Of Bengal' 'Mid-Pacifc Ocean' 'Slovenia'\n",
      " 'Curacao' 'Italy / Croatia' 'Barbados' 'Monaco' 'Guyana' 'Haiti'\n",
      " 'San Domingo' 'Ireland' 'Kuwait' 'Libya' 'Yemen ' 'Mediterranean Sea'\n",
      " 'Falkland Islands' 'Crete' 'Cyprus' 'Egypt ' 'Burma' 'Lebanon' 'Paraguay'\n",
      " 'British New Guinea' 'Ocean' 'Georgia' 'Syria' 'Tuvalu' 'Guinea'\n",
      " 'Equatorial Guinea / Cameroon' 'Cook Islands' 'Algeria' 'Coast Of Africa'\n",
      " 'Tasman Sea' 'Ghana' 'St Helena' 'Greenland' 'Sweden' 'Iceland'\n",
      " 'Between Portugal & India' 'Djibouti' 'Bahrein' 'Korea' 'Asia'\n",
      " 'Ceylon (Sri Lanka)']\n"
     ]
    }
   ],
   "source": [
    "country = df[\"Country\"]\n",
    "for x in range(len(country)):\n",
    "    if country[x] == \"Nan\":\n",
    "        df[\"Country\"] = \"Unknown\"\n",
    "    if re.search(\"(?i)\\w\\?\",country[x]):\n",
    "        country[x] = re.sub(\"\\?\",\"\",country[x])\n",
    "        df[\"Country\"][x] = country[x].title()\n",
    "    if country[x]!=\"USA\" and country[x] != \"UNITED ARAB EMIRATES (UAE)\":\n",
    "        df[\"Country\"][x] = country[x].title()\n",
    "    \n",
    "\n",
    "print(df[\"Country\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ": Ben Stratton\n",
      ": Ben Raines\n",
      ": Grant Wardell\n",
      "16' Dreamcatcher. : Ian Bussus\n",
      "4-m runabout. : Allen Gade\n",
      "4.9 m fibreglass boat. : Jack Siverling\n",
      ": Hasan Olta\n",
      "12 m fishing boat. : Henry Tervo\n",
      ":     Mr. Maciotta\n"
     ]
    }
   ],
   "source": [
    "names = df[\"Name\"].tolist()\n",
    "for n in range(len(names)):\n",
    "    names[n] = names[n].strip()\n",
    "    if re.search(\"male*\",names[n]) or re.search(\"boy.*\",names[n]) or re.search(\"nan$\",names[n]):\n",
    "        df[\"Name\"][n] = \"Unknown\"\n",
    "    else:\n",
    "        if re.search(\"Occupant:+\",names[n]):\n",
    "            names[n] = re.sub(\"Occupant\",\"\",names[n])\n",
    "            print(names[n])\n",
    "    \n",
    "#df[\"Name\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################### SURVIVAL ###################################################\n",
    "\n",
    "survival = df[\"Fatal (Y/N)\"]\n",
    "serie = F.Fatality(survival)\n",
    "#print(df[\"Survival\"].value_counts())\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_new' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-415-fcea98100da4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#check unique values to unify time information\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#change values in %%h%%m format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df_new' is not defined"
     ]
    }
   ],
   "source": [
    "################################################### TIME #############################################################\n",
    "\n",
    "#check unique values to unify time information\n",
    "\n",
    "for t in range(0,len(df_new[\"Time\"])):\n",
    "    time = df_new[\"Time\"][t]\n",
    "#change values in %%h%%m format\n",
    "    if re.search(\"\\d\\d+\",time):\n",
    "        split = (re.split(\"h\",time))\n",
    "        if split[0] < \"12\":\n",
    "            df_new[\"Time\"][t] = \"Morning\"\n",
    "        elif split[0]>\"12\" and split[0]<\"16\":\n",
    "            df_new[\"Time\"][t] = \"Afternoon\"\n",
    "        elif split[0]>\"16\" and split[0]<\"20\":\n",
    "            df_new[\"Time\"][t]=\"Evening\"\n",
    "        else:\n",
    "            df_new[\"Time\"][t] = \"Night\"    \n",
    "#change other formats\n",
    "    Morning = [\"Dawn\",\"AM\",\"A.M.\",\"daybreak\",\"morning\"]\n",
    "    Afternoon = [\"After\",\"Midday\",\"noon\",\"lunch\",\"Daytime\"]\n",
    "    Evening = [\"P.M.\",\"PM\",\"Evening\",\"dusk\",\"sunset\",\"sundown\"]\n",
    "    Night = [\"night\",\"Dark\"]\n",
    "    for m in Morning:\n",
    "        F.find_Time(df_new,\"Time\",time,t,m,\"Morning\")\n",
    "    for a in Afternoon:\n",
    "        F.find_Time(df_new,\"Time\",time,t,a,\"Afternoon\")\n",
    "    for e in Evening:\n",
    "        F.find_Time(df_new,\"Time\",time,t,e,\"Evening\")        \n",
    "    for n in Night:\n",
    "        F.find_Time(df_new,\"Time\",time,t,n,\"Night\")            \n",
    "                        \n",
    "                        \n",
    "                        \n",
    "    unknown = [\"x\",\"0\",\"--\",\"\\xa0\",\"  \",\"   \",\" \"]\n",
    "    for u in unknown:\n",
    "        if re.match(\"(?i)\"+u,time):\n",
    "            F.find_Time(df_new,\"Time\",time,t,u,\"Unknown\")\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_new[\"Time\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
